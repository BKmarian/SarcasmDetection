{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pydotplus\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from gensim.models import KeyedVectors\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional,GRU\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.layers import  Flatten, Attention\n",
    "from sklearn.metrics import  confusion_matrix,f1_score,accuracy_score\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/sarcasm/data/clean/train.csv')\n",
    "cv = pd.read_csv('../input/sarcasm/data/clean/cv.csv')\n",
    "test = pd.read_csv('../input/sarcasm/data/clean/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train['comment'] = train['comment'].astype(str)\n",
    "cv['comment'] = cv['comment'].astype(str)\n",
    "test['comment'] = test['comment'].astype(str)\n",
    "\n",
    "train['author'] = train['author'].astype(str)\n",
    "cv['author'] = cv['author'].astype(str)\n",
    "test['author'] = test['author'].astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(train['comment'].values)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoded_comments_train = t.texts_to_sequences(train['comment'])\n",
    "encoded_comments_cv = t.texts_to_sequences(cv['comment'])\n",
    "encoded_comments_test = t.texts_to_sequences(test['comment'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_sent_length = 512\n",
    "padded_comments_train = pad_sequences(encoded_comments_train, maxlen=max_sent_length, padding='post')\n",
    "padded_comments_cv = pad_sequences(encoded_comments_cv, maxlen=max_sent_length, padding='post')\n",
    "padded_comments_test = pad_sequences(encoded_comments_test, maxlen=max_sent_length, padding='post')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train = train['label'].values\n",
    "y_cv = cv['label'].values\n",
    "y_test = test['label'].values\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_cv = to_categorical(y_cv, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format('../input/wordvec/GoogleNews-vectors-negative300.bin', binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix_w2v = np.zeros((vocab_size, 300))\n",
    "for word, i in t.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = w2v_model[word]\n",
    "    except:\n",
    "        embedding_vector = [0]*300\n",
    "\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix_w2v[i] = embedding_vector\n",
    "\n",
    "embedding_matrix_w2v.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#tensorboard = TensorBoard(log_dir='lstm_model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_f1_m',\n",
    "                              mode = 'max',\n",
    "                              factor=0.5,\n",
    "                              patience=5,\n",
    "                              min_lr=0.0001,\n",
    "                              verbose=10)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"lstm_model.h5\",\n",
    "                               monitor=\"val_f1_m\",\n",
    "                               mode=\"max\",\n",
    "                               save_best_only = True,\n",
    "                               verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_f1_m',\n",
    "                            mode=\"max\",\n",
    "                            min_delta = 0,\n",
    "                            patience = 5,\n",
    "                            verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_data = Input(shape=(max_sent_length,), name='main_input')\n",
    "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix_w2v], trainable=False)(input_data)\n",
    "dropout_1 = Dropout(0.3)(embedding_layer)\n",
    "bilstm = Bidirectional(LSTM(100, return_sequences = True))(dropout_1)\n",
    "dropout_2 = Dropout(0.3)(bilstm)\n",
    "bilstm2 = Bidirectional(LSTM(100, return_sequences = True))(dropout_2)\n",
    "dropout_3 = Dropout(0.3)(bilstm2)\n",
    "max_2 = Flatten()(dropout_3)\n",
    "flatten = Flatten()(max_2)\n",
    "out = Dense(2, activation='softmax', name='fully_connected')(flatten)\n",
    "\n",
    "lstm_model = Model(inputs=[input_data], outputs=[out])\n",
    "\n",
    "# print(lstm_model.summary())\n",
    "\n",
    "#keras.utils.vis_utils.pydot = pyd\n",
    "#plot_model(lstm_model, to_file='lstm_model.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=[f1_score,accuracy_score])\n",
    "\n",
    "lstm_model_h1 = lstm_model.fit(padded_comments_train, y_train,\n",
    "               batch_size=64,\n",
    "               epochs=50,\n",
    "               verbose=1, callbacks=[checkpoint, earlystop, reduce_lr], #tensorboard\n",
    "               validation_data=(padded_comments_cv, y_cv))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(padded_comments_cv)\n",
    "print(y_cv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score_1 = lstm_model.evaluate(padded_comments_test, y_test)\n",
    "print(score_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnf_mat = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(lstm_model.predict(padded_comments_test), axis=1))\n",
    "\n",
    "print(cnf_mat)\n",
    "sns.heatmap(cnf_mat, annot=True, fmt='g', linewidths=.5, xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "\n",
    "    #%%\n",
    "\n",
    "plt.plot(lstm_model_h1.history['f1_m'][1:])\n",
    "plt.plot(lstm_model_h1.history['val_f1_m'][1:])\n",
    "plt.title('Model metric')\n",
    "plt.ylabel('F1 metric')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','Validation'], loc='upper left')\n",
    "plt.savefig('bilstm_f1_100_100_512.png')\n",
    "#plt.show()\n",
    "plt.clf()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(lstm_model_h1.history['loss'][1:])\n",
    "plt.plot(lstm_model_h1.history['val_loss'][1:])\n",
    "plt.title('Model Los')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','Validation'], loc='upper left')\n",
    "plt.savefig('Bilstm_Loss_100_100_512.png')\n",
    "#plt.show()\n",
    "plt.clf()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23960.745118,
   "end_time": "2022-04-05T15:43:24.744549",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-05T09:04:03.999431",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}